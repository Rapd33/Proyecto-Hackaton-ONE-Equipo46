# DataScience - Microservicio de Predicci√≥n de Churn

Microservicio de Machine Learning desarrollado con FastAPI que predice la probabilidad de abandono (churn) de clientes en el sector de telecomunicaciones. Utiliza un modelo GradientBoosting entrenado con scikit-learn.

## üöÄ Caracter√≠sticas

- **API REST con FastAPI**: Endpoints r√°pidos y documentados autom√°ticamente
- **Modelo GradientBoosting**: Pipeline completo con preprocesamiento y clasificaci√≥n
- **Modo Mock**: Predicciones basadas en reglas cuando el modelo no est√° disponible
- **Arquitectura Hexagonal**: C√≥digo limpio y mantenible
- **CORS Configurado**: Listo para integrarse con el backend Spring Boot
- **Health Check**: Monitoreo del estado del servicio y modelo
- **Validaci√≥n con Pydantic**: Schemas robustos para datos de entrada/salida
- **Documentaci√≥n Swagger**: Interfaz interactiva para probar la API

## üìã Requisitos Previos

- **Python**: versi√≥n 3.9 o superior
- **pip**: gestor de paquetes de Python
- **Git**: para clonar el repositorio

Verifica la versi√≥n de Python:

```bash
python --version
```

## üõ†Ô∏è Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd Proyecto-Hackaton-ONE-Equipo46/DataScience
```

### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual
# En Windows:
.venv\Scripts\activate

# En Linux/Mac:
source .venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

Esto instalar√°:
- FastAPI y Uvicorn (servidor)
- Pydantic (validaci√≥n)
- scikit-learn, pandas, numpy (ML)
- Otras utilidades

## üéÆ Ejecuci√≥n

### Iniciar el Servidor

```bash
# Desde la ra√≠z del proyecto DataScience
python src/infrastructure/adapters/input/api/main.py
```

O alternativamente:

```bash
uvicorn src.infrastructure.adapters.input.api.main:app --reload --host 0.0.0.0 --port 8000
```

El servicio estar√° disponible en: **http://127.0.0.1:8000**

### Verificar que Funciona

Accede a la documentaci√≥n Swagger:

```
http://127.0.0.1:8000/docs
```

O prueba el health check:

```bash
curl http://127.0.0.1:8000/health
```

## üìÅ Estructura del Proyecto

```
DataScience/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ domain/                              # Capa de dominio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                   # Pydantic schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ports/                           # Interfaces (vac√≠o por ahora)
‚îÇ   ‚îú‚îÄ‚îÄ application/                         # Casos de uso (vac√≠o por ahora)
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/                      # Infraestructura
‚îÇ       ‚îú‚îÄ‚îÄ adapters/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ input/
‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.py              # FastAPI application
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ output/
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ ml_model/
‚îÇ       ‚îÇ           ‚îî‚îÄ‚îÄ predictor.py         # Clase ChurnPredictor
‚îÇ       ‚îî‚îÄ‚îÄ config/                          # Configuraci√≥n (vac√≠o por ahora)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ trained/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ churn_prediction_pipeline.pkl    # Modelo entrenado
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/                           # Artefactos del modelo
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py                       # Script para entrenar modelo
‚îÇ   ‚îî‚îÄ‚îÄ migrate_csv_to_db.py                 # Migrar CSV a SQLite
‚îú‚îÄ‚îÄ data/                                    # Datos (no incluidos en repo)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                 # Datos originales
‚îÇ   ‚îî‚îÄ‚îÄ processed/                           # Datos procesados
‚îú‚îÄ‚îÄ requirements.txt                         # Dependencias Python
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md                                # Este archivo
```

## üèóÔ∏è Arquitectura

### Componentes Principales

#### 1. **FastAPI Application** (`main.py`)
- Configura la aplicaci√≥n FastAPI
- Define los endpoints de la API
- Maneja CORS y middleware
- Inicializa el predictor al arranque

#### 2. **ChurnPredictor** (`predictor.py`)
- Carga el modelo entrenado desde disco
- Encapsula la l√≥gica de predicci√≥n
- Implementa modo mock cuando no hay modelo
- Calcula niveles de riesgo

#### 3. **Pydantic Schemas** (`schemas.py`)
- `CustomerData`: Valida datos de entrada
- `PredictionResponse`: Estructura de respuesta
- `HealthResponse`: Estado del servicio
- `ModelInfo`: Informaci√≥n del modelo

### Flujo de Predicci√≥n

1. Cliente env√≠a POST a `/predict` con datos del cliente
2. Pydantic valida los datos autom√°ticamente
3. `main.py` convierte los datos a diccionario
4. `ChurnPredictor` realiza la predicci√≥n
5. Respuesta se valida con `PredictionResponse`
6. Cliente recibe JSON con predicci√≥n y probabilidad

## üåê Endpoints de la API

### Root

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| GET | `/` | Informaci√≥n b√°sica de la API |

### Health & Monitoring

| M√©todo | Endpoint | Descripci√≥n | Respuesta |
|--------|----------|-------------|-----------|
| GET | `/health` | Health check del servicio | `HealthResponse` |
| GET | `/model/info` | Informaci√≥n del modelo cargado | `ModelInfo` |
| GET | `/debug/model-status` | Estado detallado del modelo (debug) | JSON |

### Predicci√≥n

| M√©todo | Endpoint | Descripci√≥n | Request | Response |
|--------|----------|-------------|---------|----------|
| POST | `/predict` | Predecir churn de un cliente | `CustomerData` | `PredictionResponse` |

### Ejemplo de Uso

#### Realizar una Predicci√≥n

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "tenure": 12,
    "MonthlyCharges": 65.5,
    "TotalCharges": 786.0,
    "SeniorCitizen": 0,
    "Contract": "Month-to-month",
    "InternetService": "Fiber optic",
    "PaymentMethod": "Electronic check",
    "TechSupport": "No",
    "OnlineSecurity": "No",
    "Partner": "Yes",
    "Dependents": "No"
  }'
```

**Respuesta:**

```json
{
  "prediction": 1,
  "churn_probability": 0.7534,
  "risk_level": "Alto"
}
```

#### Health Check

```bash
curl http://127.0.0.1:8000/health
```

**Respuesta:**

```json
{
  "status": "healthy",
  "model_loaded": true,
  "message": "Servicio operativo con modelo cargado"
}
```

## üîß Configuraci√≥n

### Variables del Modelo

Las variables requeridas para predicci√≥n son:

**Num√©ricas:**
- `tenure`: Meses de antig√ºedad del cliente (‚â• 0)
- `MonthlyCharges`: Cargo mensual en USD (> 0)
- `TotalCharges`: Cargos totales acumulados (‚â• 0)
- `SeniorCitizen`: Si es ciudadano senior (0 o 1)

**Categ√≥ricas:**
- `Contract`: "Month-to-month", "One year", "Two year"
- `InternetService`: "DSL", "Fiber optic", "No"
- `PaymentMethod`: "Electronic check", "Mailed check", "Bank transfer (automatic)", "Credit card (automatic)"
- `TechSupport`: "No", "Yes", "No internet service"

**Opcionales (con valores por defecto):**
- `OnlineSecurity`: "No", "Yes", "No internet service" (default: "No")
- `Partner`: "No", "Yes" (default: "No")
- `Dependents`: "No", "Yes" (default: "No")

### CORS

El servicio acepta peticiones desde:
- `http://localhost:8080` (Backend Spring Boot)
- `http://localhost:4200` (Frontend Angular)

Para modificar, edita en [`main.py`](src/infrastructure/adapters/input/api/main.py):

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8080", "http://localhost:4200"],
    ...
)
```

## ü§ñ Modelo de Machine Learning

### Caracter√≠sticas

- **Algoritmo**: GradientBoosting
- **Features**: 11 variables (4 num√©ricas, 7 categ√≥ricas)
- **Preprocesamiento**: StandardScaler para num√©ricas, OneHotEncoder para categ√≥ricas
- **Pipeline**: Completo con transformaciones y modelo

### Entrenar/Regenerar el Modelo

Si necesitas reentrenar el modelo:

```bash
# Aseg√∫rate de tener el dataset en data/raw/telco_churn.csv
python scripts/train_model.py
```

Esto generar√° un nuevo `churn_prediction_pipeline.pkl` en `models/trained/`.

### Modo Mock

Cuando el modelo no est√° disponible, el servicio usa predicciones basadas en reglas:

- **Alto riesgo (75%)**: tenure < 12 meses Y contrato mes a mes
- **Riesgo medio-alto (65%)**: tenure < 24 meses Y cargo mensual > $70
- **Bajo riesgo (15%)**: Contrato de dos a√±os
- **Riesgo medio (45%)**: Otros casos

## üìä Scripts √ötiles

### Migrar CSV a SQLite

```bash
python scripts/migrate_csv_to_db.py
```

Convierte el CSV de clientes a base de datos SQLite para el backend.

### Entrenar Modelo

```bash
python scripts/train_model.py
```

Entrena un nuevo modelo GradientBoosting con los datos de telco.

## üêõ Soluci√≥n de Problemas

### El servidor no inicia

```bash
# Verifica que el entorno virtual est√© activado
.venv\Scripts\activate   # Windows
source .venv/bin/activate  # Linux/Mac

# Reinstala dependencias
pip install -r requirements.txt
```

### Error "Model not found"

El servicio funcionar√° en modo mock. Si quieres usar el modelo real:

1. Verifica que existe `models/trained/churn_prediction_pipeline.pkl`
2. Si no existe, entrena el modelo con `python scripts/train_model.py`

### Error de importaci√≥n de m√≥dulos

```bash
# Aseg√∫rate de ejecutar desde la ra√≠z de DataScience
cd DataScience
python src/infrastructure/adapters/input/api/main.py
```

### Puerto 8000 ocupado

```bash
# Usa otro puerto
uvicorn src.infrastructure.adapters.input.api.main:app --port 8001
```

## üì¶ Dependencias Principales

| Paquete | Versi√≥n | Prop√≥sito |
|---------|---------|-----------|
| fastapi | 0.128.0 | Framework web |
| uvicorn | 0.40.0 | Servidor ASGI |
| pydantic | 2.12.5 | Validaci√≥n de datos |
| scikit-learn | 1.6.1 | Machine Learning |
| pandas | 2.3.3 | Manipulaci√≥n de datos |
| numpy | 2.4.0 | C√°lculos num√©ricos |
| joblib | 1.5.3 | Serializaci√≥n del modelo |

Ver todas las dependencias en [`requirements.txt`](requirements.txt).

## üöÄ Despliegue

### Docker (Opcional)

Crear `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["python", "src/infrastructure/adapters/input/api/main.py"]
```

Build y run:

```bash
docker build -t churn-ml-service .
docker run -p 8000:8000 churn-ml-service
```

### Producci√≥n

Para producci√≥n, usa Gunicorn con workers:

```bash
pip install gunicorn

gunicorn src.infrastructure.adapters.input.api.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000
```

## üìù Documentaci√≥n API

Una vez el servicio est√© corriendo, accede a:

- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

Aqu√≠ puedes:
- Ver todos los endpoints
- Probar las APIs directamente
- Ver esquemas de request/response
- Obtener ejemplos de uso

## üß™ Testing (Futuro)

Estructura para tests:

```bash
tests/
‚îú‚îÄ‚îÄ test_api.py           # Tests de endpoints
‚îú‚îÄ‚îÄ test_predictor.py     # Tests del predictor
‚îî‚îÄ‚îÄ test_schemas.py       # Tests de validaci√≥n
```

Ejecutar tests:

```bash
pytest tests/
```

## üìù Licencia

Este proyecto fue desarrollado como parte del Hackaton ONE - Equipo 46.

## üìû Contacto

Para preguntas o soporte, contacta al equipo de desarrollo.

---

**Desarrollado con ‚ù§Ô∏è por el Equipo 46 - Hackaton ONE**
