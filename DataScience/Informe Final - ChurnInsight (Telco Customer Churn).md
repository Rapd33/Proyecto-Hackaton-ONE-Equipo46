# üìä Informe Final ‚Äì ChurnInsight (Telco Customer Churn)

## üåê Proyecto

- **Nombre:** ChurnInsight ‚Äî Predicci√≥n de Cancelaci√≥n de Clientes
- **Dominio:** Telecomunicaciones / Servicios por Suscripci√≥n
- **Equipo:** Equipo 46 ‚Äì Hackathon ONE / NoCountry


Empresa: Teleco
- Problema: Alta tasa de cancelaci√≥n de clientes (churn)
- Objetivo del proyecto: Analizar el comportamiento de clientes para identificar patrones asociados a la cancelaci√≥n del servicio (churn), como base para entrenar un modelo predictivo capaz de prever qu√© clientes tienen mayor probabilidad churn.

- La empresa quiere anticiparse al problema de la cancelaci√≥n, respondiendo preguntas como:

1. ¬øQuienes son los clientes con mayor riesgo de evasi√≥n?
2. ¬øQu√© variables influyen m√°s en este comportamiento?
3. ¬øQu√© perfil de cliente debemos cuidar con mayor atenci√≥n?

Este conocimiento es necesario para ayudar a implemenar acciones de retenci√≥n y estrategias personalizadas

---

## üöÄ 1. Resumen Ejecutivo

El presente informe documenta el tratamiento realizado a los datos hasta llegar al modelo y propuesta de estrategias por rangos de probabilidad del proyecto **ChurnInsight**. El modelo se dispone en un archivo pkl para consumo mediante microservicio.

A partir del dataset **Telco Customer Churn**, se realiz√≥ un proceso completo de:

* An√°lisis exploratorio de datos (EDA)
* Selecci√≥n y justificaci√≥n de variables
* Feature engineering
* Entrenamiento y evaluaci√≥n de modelos
* Construcci√≥n de un pipeline reproducible
* Serializaci√≥n del modelo para integraci√≥n con Backend
* Estrategias propuestas de retenci√≥n de cliente

El resultado final es un **modelo funcional**, interpretable y listo para ser consumido por un microservicio. Y un cuadro de Estrategias Propuestas por rangos de probabilidades.

---

## üß† 2. Objetivo del Proyecto

* Identificar clientes con **alto riesgo de cancelaci√≥n**.
* Retornar una **predicci√≥n binaria** (cancela / no cancela) junto con una **probabilidad asociada**.
* Facilitar la toma de decisiones mediante **estrategias de retenci√≥n basadas en rangos de riesgo**.

---

## üìÇ 3. Dataset Utilizado

* **Fuente:** Kaggle ‚Äì Telco Customer Churn
* **Registros:** ~7.000 clientes
* **Variable objetivo:** `Churn` (Yes / No)
* **Tipo de variables:** num√©ricas, binarias y categ√≥ricas

Variables clave incluyen:

* Antig√ºedad del cliente (`tenure`)
* Cargos mensuales (`MonthlyCharges`)
* Tipo de contrato (`Contract`)
* M√©todo de pago (`PaymentMethod`)
* Servicios adicionales (`TechSupport`, `OnlineSecurity`, etc.)

---

## üîç 4. An√°lisis Exploratorio de Datos (EDA)

üëâ [Ver Dasboard EDA](https://lookerstudio.google.com/embed/reporting/731adedd-8ee2-48d0-9566-bae83407fd58/page/FgvlF)

Durante el EDA se identificaron patrones claros asociados al churn:

* Clientes con **contrato mes a mes** , driver m√°s cr√≠tico presentan la mayor tasa de cancelaci√≥n. Tasa de churn alta (42.71%).
* **Menor antig√ºedad (tenure bajo)** est√° fuertemente asociada al churn. (media de 18 meses vs. 37.6 meses para los que no cancelan)
* **Cargos mensuales altos** incrementan la probabilidad de cancelaci√≥n.
* Servicios como **TechSupport y OnlineSecurity** reducen significativamente el churn.
* Variables como `gender` o servicios de streaming mostraron **bajo impacto predictivo**.

Este an√°lisis permiti√≥ **descartar variables sin valor predictivo** y reducir ruido en el modelo.

**Segmento de Mayor Riesgo**: Clientes nuevos, con contrato mensual, factura alta, sin soporte ni seguridad, que pagan con cheque electr√≥nico.

---

## üß© 5. Selecci√≥n Final de Variables

| Variable        | Tipo       | Uso | Justificaci√≥n                      |
| --------------- | ---------- | --- | ---------------------------------- |
| tenure          | Num√©rica   | ‚úÖ   | Relaci√≥n inversa fuerte con churn  |
| MonthlyCharges  | Num√©rica   | ‚úÖ   | Cargos altos aumentan churn        |
| SeniorCitizen   | Binaria    | ‚úÖ   | Impacto moderado                   |
| Contract        | Categ√≥rica | ‚úÖ   | Month-to-month concentra churn     |
| InternetService | Categ√≥rica | ‚úÖ   | Fibra √≥ptica con mayor cancelaci√≥n |
| PaymentMethod   | Categ√≥rica | ‚úÖ   | Electronic check asociado a churn  |
| TechSupport     | Categ√≥rica | ‚úÖ   | Reduce churn                       |
| OnlineSecurity  | Categ√≥rica | ‚ö†Ô∏è  | Impacto secundario                 |
| TotalCharges    | Num√©rica   | ‚ö†Ô∏è  | Resume relaci√≥n cliente-empresa    |
| customerID      | ID         | ‚ùå   | No aporta informaci√≥n predictiva   |

---

## üõ†Ô∏è 6. Feature Engineering y Pipeline

Se construy√≥ un **pipeline completo** utilizando `scikit-learn`, asegurando reproducibilidad y correcta integraci√≥n con Backend:

* **Variables num√©ricas:** escaladas con `StandardScaler`
* **Variables binarias:** mapeadas a 0 / 1
* **Variables categ√≥ricas:** transformadas con `OneHotEncoder`

Todo el preprocesamiento y el modelo se integraron mediante un **ColumnTransformer + Pipeline**, evitando fugas de informaci√≥n.

---

## ü§ñ 7. Modelado y Evaluaci√≥n

Se validaron los modelos Regresi√≥n Log√≠stica , Random Forest , Gradient Boosting , XGBoost , LightGBM , CatBoost , KNN. Sin balanceo, luego con balanceo usando SMOTE y por ultimo Balanceo con Undersampling.


## Cuadro Comparativo Detallado de M√©tricas por Modelo (sin Balanceo)

|  M√©trica              | Regresi√≥n Log√≠stica | Random Forest | Gradient Boosting | XGBoost | LightGBM | CatBoost | KNN   |
|:----------------------|:--------------------|:--------------|:------------------|:--------|:---------|:---------|:------|
| Accuracy              | 0.79                | 0.77          | **0.8**           | 0.79    | **0.8**  | 0.8      | 0.76  |
| AUC                   | **0.71**            | 0.67          | **0.71**          | 0.7     | **0.72** | **0.71** | 0.68  |
| Precision (No Churn)  | **0.84**            | 0.82          | **0.84**          | **0.84**| **0.84** | **0.84** | 0.82  |
| Recall (No Churn)     | **0.89**            | 0.88          | **0.9**           | 0.88    | **0.89** | **0.9**  | 0.86  |
| F1-Score (No Churn)   | **0.86**            | **0.85**      | **0.87**          | 0.86    | 0.87     | 0.87     | 0.84  |
| Support (No Churn)    | 1035                | 1035          | 1035              | 1035    | 1035     | 1035     | 1035  |
| Precision (Churn)     | 0.63                | 0.59          | **0.66**          | 0.61    | 0.64     | 0.65     | 0.56  |
| Recall (Churn)        | 0.53                | 0.47          | 0.52              | 0.52    | **0.54** | 0.53     | 0.49  |
| F1-Score (Churn)      | 0.58                | 0.52          | **0.59**          | 0.56    | **0.59** | 0.58     | 0.52  |
| Support (Churn)       | 374                 | 374           | 374               | 374     | 374      | 374      | 374   |


El rendimiento de los modelos evaluados sin SMOTE muestra que, si bien la precisi√≥n general es relativamente alta (alrededor del 76% al 80%), los modelos luchan consistentemente con la predicci√≥n de la clase minoritaria 'Churn'. Gradient Boosting, LightGBM y CatBoost generalmente exhiben un rendimiento ligeramente mejor en m√©tricas clave como AUC y F1-Score para la clase 'Churn' en comparaci√≥n con otros modelos.

## Cuadro ComparativoDetallado de M√©tricas por Modelo (Balanceo con SMOTE)


| M√©trica                 | Regresi√≥n Log√≠stica | Random Forest | Gradient Boosting | XGBoost | LightGBM | CatBoost | KNN |
|:------------------------|:--------------------|:--------------|:------------------|:--------|:---------|:---------|:----|
| Accuracy                | 0.73                | 0.75          | 0.75              | 0.76    | **0.76** | **0.76** | 0.74|
| AUC                     | **0.84**            | 0.81          | **0.84**          | 0.82    | **0.84** | 0.83     | 0.80|
| Precision (No Churn)    | 0.91                | 0.85          | **0.91**          | 0.87    | 0.89     | 0.88     | 0.88|
| Recall (No Churn)       | 0.70                | 0.80          | 0.73              | 0.79    | 0.77     | **0.79** | 0.75|
| F1-Score (No Churn)     | 0.79                | 0.83          | 0.81              | **0.83**| **0.83** | **0.83** | 0.81|
| Precision (Churn)       | 0.50                | 0.53          | 0.51              | **0.54**| **0.54** | **0.54** | 0.51|
| Recall (Churn)          | **0.80**            | 0.61          | **0.79**          | 0.68    | 0.74     | 0.71     | 0.72|
| F1-Score (Churn)        | 0.61                | 0.57          | **0.62**          | 0.60    | **0.62** | 0.61     | 0.60|
| Support (No Churn)      | 1035                | 1035          | 1035              | 1035    | 1035     | 1035     | 1035|
| Support (Churn)         | 374                 | 374           | 374               | 374     | 374      | 374      | 374 |

Tras el balanceo, observamos una redistribuci√≥n en las m√©tricas, donde el Recall para 'Churn' generalmente mejora, aunque a veces a expensas de una ligera disminuci√≥n en la Precision para 'No Churn' o el Accuracy general.

resumen del rendimiento de cada modelo, enfoc√°ndonos en las m√©tricas clave para la clase 'Churn' (Precision, Recall, F1-Score) y la capacidad general de discriminaci√≥n (AUC).

Observaciones Clave:

Recall (Churn) - Detecci√≥n de Falsos Negativos: La Regresi√≥n Log√≠stica (SMOTE) (0.80) y Gradient Boosting (SMOTE) (0.79) destacan con los valores de Recall m√°s altos para la clase 'Churn'. Esto significa que son los modelos m√°s efectivos en identificar a la mayor√≠a de los clientes que realmente abandonar√°n el servicio, lo cual es crucial en problemas de churn para permitir intervenciones proactivas.

Precision (Churn) - Minimizaci√≥n de Falsos Positivos: XGBoost (SMOTE), LightGBM (SMOTE), y CatBoost (SMOTE) muestran la mejor Precision para la clase 'Churn' (0.54). Una mayor precisi√≥n es importante para asegurar que los recursos de retenci√≥n no se malgasten en clientes que el modelo predice que se ir√°n, pero que en realidad no lo har√°n.

F1-Score (Churn) - Balance entre Precision y Recall: LightGBM (SMOTE) y Gradient Boosting (SMOTE) lideran con el F1-Score m√°s alto (0.62), indicando un buen equilibrio entre Precision y Recall para la clase 'Churn'. La Regresi√≥n Log√≠stica (SMOTE) tambi√©n tiene un F1-Score competitivo (0.61).

AUC - Capacidad Discriminatoria General: La Regresi√≥n Log√≠stica (SMOTE), Gradient Boosting (SMOTE) y LightGBM (SMOTE) comparten los valores de AUC m√°s altos (0.84), lo que sugiere que son los mejores en distinguir entre las clases 'Churn' y 'No Churn' en general.

Accuracy General: LightGBM (SMOTE), CatBoost (SMOTE) y XGBoost (SMOTE) obtienen las mayores puntuaciones de Accuracy (0.76), seguidos de cerca por Random Forest (SMOTE) y Gradient Boosting (SMOTE) (0.75). Sin embargo, en un contexto de desbalance, esta m√©trica es menos prioritaria que las espec√≠ficas de la clase minoritaria.

Conclusi√≥n General
La elecci√≥n del modelo final depender√° en gran medida de la prioridad de negocio:

Si el objetivo principal es detectar a la mayor cantidad posible de clientes en riesgo (priorizando el Recall para 'Churn'), la Regresi√≥n Log√≠stica (SMOTE) o Gradient Boosting (SMOTE) ser√≠an las mejores opciones.
Si se busca un equilibrio s√≥lido entre la detecci√≥n y la fiabilidad de las predicciones (priorizando el F1-Score y una Precision aceptable para 'Churn'), LightGBM (SMOTE) y Gradient Boosting (SMOTE) se presentan como los modelos m√°s robustos.

## Resumen de la tabla comparativa de modelos con SMOTE

### Impacto del Balanceo de Clases con SMOTE
La aplicaci√≥n de SMOTE ha tenido un impacto notable en el rendimiento de los modelos, especialmente en su capacidad para identificar la clase minoritaria ('Churn'). Antes de SMOTE, los modelos tend√≠an a mostrar una alta precisi√≥n general (Accuracy) pero un Recall m√°s bajo para la clase 'Churn', lo que se deb√≠a al desbalance de clases. Tras el balanceo, observamos una redistribuci√≥n en las m√©tricas, donde el Recall para 'Churn' generalmente mejora, aunque a veces a expensas de una ligera disminuci√≥n en la Precision para 'No Churn' o el Accuracy general.

### An√°lisis del Rendimiento de Cada Modelo (con SMOTE)

A continuaci√≥n, se presenta un resumen del rendimiento de cada modelo, enfoc√°ndonos en las m√©tricas clave para la clase 'Churn' (Precision, Recall, F1-Score) y la capacidad general de discriminaci√≥n (AUC).

**Observaciones Clave:**

*   **Recall (Churn) - Detecci√≥n de Falsos Negativos:** La **Regresi√≥n Log√≠stica (SMOTE)** (0.80) y **Gradient Boosting (SMOTE)** (0.79) destacan con los valores de Recall m√°s altos para la clase 'Churn'. Esto significa que son los modelos m√°s efectivos en identificar a la mayor√≠a de los clientes que realmente abandonar√°n el servicio, lo cual es crucial en problemas de churn para permitir intervenciones proactivas.

*   **Precision (Churn) - Minimizaci√≥n de Falsos Positivos:** **XGBoost (SMOTE), LightGBM (SMOTE), y CatBoost (SMOTE)** muestran la mejor Precision para la clase 'Churn' (0.54). Una mayor precisi√≥n es importante para asegurar que los recursos de retenci√≥n no se malgasten en clientes que el modelo predice que se ir√°n, pero que en realidad no lo har√°n.

*   **F1-Score (Churn) - Balance entre Precision y Recall:** **LightGBM (SMOTE)** y **Gradient Boosting (SMOTE)** lideran con el F1-Score m√°s alto (0.62), indicando un buen equilibrio entre Precision y Recall para la clase 'Churn'. La Regresi√≥n Log√≠stica (SMOTE) tambi√©n tiene un F1-Score competitivo (0.61).

*   **AUC - Capacidad Discriminatoria General:** La **Regresi√≥n Log√≠stica (SMOTE), Gradient Boosting (SMOTE) y LightGBM (SMOTE)** comparten los valores de AUC m√°s altos (0.84), lo que sugiere que son los mejores en distinguir entre las clases 'Churn' y 'No Churn' en general.

*   **Accuracy General:** **LightGBM (SMOTE), CatBoost (SMOTE)** y **XGBoost (SMOTE)** obtienen las mayores puntuaciones de Accuracy (0.76), seguidos de cerca por Random Forest (SMOTE) y Gradient Boosting (SMOTE) (0.75). Sin embargo, en un contexto de desbalance, esta m√©trica es menos prioritaria que las espec√≠ficas de la clase minoritaria.

### Conclusi√≥n General
La elecci√≥n del modelo final depender√° en gran medida de la prioridad de negocio:

*   Si el objetivo principal es **detectar a la mayor cantidad posible de clientes en riesgo** (priorizando el **Recall** para 'Churn'), la **Regresi√≥n Log√≠stica (SMOTE)** o **Gradient Boosting (SMOTE)** ser√≠an las mejores opciones.
*   Si se busca un **equilibrio s√≥lido entre la detecci√≥n y la fiabilidad de las predicciones** (priorizando el **F1-Score** y una Precision aceptable para 'Churn'), **LightGBM (SMOTE)** y **Gradient Boosting (SMOTE)** se presentan como los modelos m√°s robustos.

SMOTE ha demostrado ser una herramienta efectiva para mejorar la detecci√≥n de la clase minoritaria, haciendo que los modelos sean m√°s √∫tiles para las estrategias de retenci√≥n de clientes.

El modelo seleccionado es **Gradient Boosting**, el objetivo es **detectar a la mayor cantidad posible de clientes en riesgo** (priorizando el **Recall** para 'Churn') y se busca tam bi√©n un **equilibrio s√≥lido entre la detecci√≥n y la fiabilidad de las predicciones** (priorizando el **F1-Score** y una Precision aceptable para 'Churn')

## Cuadro Comparativo Detallado de M√©tricas por Modelo (Balanceo Undersampling)

| M√©trica                 | Regresi√≥n Log√≠stica | Random Forest | Gradient Boosting | XGBoost | LightGBM | CatBoost | KNN |
|:------------------------|:--------------------|:--------------|:------------------|:--------|:---------|:---------|:----|
| Accuracy                | 0.74                | 0.74          | 0.73              | 0.73    | **0.76** | 0.74     | 0.72|
| AUC                     | **0.84**            | 0.81          | **0.84**          | 0.82    | **0.84** | **0.84** | 0.80|
| Precision (No Churn)    | **0.91**            | 0.87          | **0.91**          | 0.88    | 0.89     | 0.90     | 0.89|
| Recall (No Churn)       | 0.70                | **0.75**      | 0.71              | 0.73    | **0.77** | 0.72     | 0.71|
| F1-Score (No Churn)     | 0.79                | 0.81          | 0.80              | 0.80    | **0.83** | 0.80     | 0.79|
| Precision (Churn)       | 0.50                | 0.50          | 0.50              | 0.50    | **0.54** | 0.51     | 0.48|
| Recall (Churn)          | **0.80**            | 0.70          | **0.80**          | 0.73    | 0.74     | 0.79     | 0.76|
| F1-Score (Churn)        | **0.61**            | 0.59          | **0.61**          | 0.59    | **0.62** | **0.62** | 0.59|
| Support (No Churn)      | 1035                | 1035          | 1035              | 1035    | 1035     | 1035     | 1035|
| Support (Churn)         | 374                 | 374           | 374               | 374     | 374      | 374      | 374 |


## Resumen: Hallazgos Clave del An√°lisis de Datos

*   **Rendimiento General (Accuracy y AUC)**: LightGBM logr√≥ la mayor precisi√≥n (Accuracy) con 0.76. Los modelos de Regresi√≥n Log√≠stica, Gradient Boosting, LightGBM y CatBoost compartieron el AUC m√°s alto de 0.84, lo que indica un fuerte poder discriminatorio general para estos modelos.
*   **Rendimiento de la Clase No Churn**: LightGBM mostr√≥ el mejor rendimiento para la clase "No Churn", con el Recall m√°s alto (0.77) y el F1-Score (0.83). Regresi√≥n Log√≠stica y Gradient Boosting tuvieron la precisi√≥n m√°s alta para "No Churn" con 0.91.
*   **Rendimiento de la Clase Churn**: Regresi√≥n Log√≠stica y Gradient Boosting lograron el Recall m√°s alto para la clase "Churn" (0.80). LightGBM y CatBoost compartieron el F1-Score m√°s alto para la clase "Churn" (0.62).
*   **Precisi√≥n para la Clase Churn**: Todos los modelos mostraron una precisi√≥n relativamente baja para la clase "Churn", siendo LightGBM el m√°s alto con 0.54, seguido de CatBoost con 0.51. Esto sugiere un desaf√≠o com√∫n entre los modelos para minimizar los falsos positivos al predecir el churn.
*   **Modelo de Bajo Rendimiento**: El modelo K-Nearest Neighbors (KNN) generalmente tuvo un rendimiento inferior en la mayor√≠a de las m√©tricas en comparaci√≥n con los otros modelos.

### Insights o Pr√≥ximos Pasos

*   LightGBM y CatBoost demuestran un fuerte equilibrio de rendimiento en varias m√©tricas para el escenario de submuestreo, lo que los convierte en candidatos prometedores para una mayor optimizaci√≥n o selecci√≥n como modelo principal.
*   La precisi√≥n consistentemente baja para la clase "Churn" en todos los modelos destaca un √°rea de mejora. Los esfuerzos futuros deben centrarse en estrategias para mejorar la capacidad del modelo para identificar correctamente a los churners sin una alta tasa de falsos positivos, potencialmente a trav√©s de ingenier√≠a de caracter√≠sticas m√°s avanzada, ajuste de umbrales o explorando diferentes t√©cnicas de aprendizaje sensibles al costo.

### Identificaci√≥n del Mejor Modelo para Clientes con Churn

Ambas t√©cnicas de balanceo, SMOTE y Undersampling, son altamente efectivas para mejorar el poder discriminatorio de los modelos en la predicci√≥n de churn, reflejado en un aumento sustancial de las puntuaciones AUC para la mayor√≠a de los modelos.

Modelos de Ensamble (Gradient Boosting, LightGBM, CatBoost) y la Regresi√≥n Log√≠stica demuestran el mejor rendimiento en t√©rminos de AUC (aproximadamente 0.84) en los escenarios balanceados, lo que indica que son los m√°s capaces de distinguir entre clientes que har√°n churn y los que no.

No se observa una ventaja clara y generalizada de SMOTE sobre Undersampling, o viceversa, en cuanto al AUC. M√°s bien, ambas t√©cnicas logran llevar a los modelos a un nivel similar de poder discriminatorio, con los modelos de mayor rendimiento manteniendo sus posiciones destacadas en ambos escenarios.

En conclusi√≥n, la aplicaci√≥n de t√©cnicas de balanceo es crucial para obtener un modelo predictivo de churn con un alto poder discriminatorio. Modelos como la Regresi√≥n Log√≠stica, **Gradient Boosting**, LightGBM y CatBoost, cuando se combinan con SMOTE o Undersampling, son las opciones m√°s robustas para esta tarea.

Metricas: 


1. Precisi√≥n (Accuracy)
![](./img/1_Metrica_Accuracy.png)

Precisi√≥n m√°s alta: Generalmente, los modelos sin balanceo (escenario 'No Balancing') tienden a mostrar una Precisi√≥n general ligeramente m√°s alta. Por ejemplo, Gradient Boosting, LightGBM y CatBoost alcanzan una Precisi√≥n del 0.80 en el escenario 'No Balancing'. En los escenarios balanceados, LightGBM y XGBoost muestran una alta precisi√≥n alrededor de 0.76.
Compromiso (Trade-off): Es importante destacar que una mayor precisi√≥n general en conjuntos de datos desbalanceados puede ser enga√±osa, ya que los modelos podr√≠an simplemente predecir la clase mayoritaria con m√°s frecuencia.

2. AUC (√Årea bajo la Curva)
![](./img/2_Metrica_AUC.png)

AUC m√°s alto: Los escenarios de SMOTE y Undersampling consistentemente producen puntuaciones AUC m√°s altas en la mayor√≠a de los modelos, lo que indica un mejor poder discriminatorio entre las clases de abandono (churn) y no abandono.

![](./img/5_ROC_AUC_SMOTE.png)

![](./img/6_ROC_AUC_UNDERSAMPLING.png)

Mejores resultados (AUC):
Regresi√≥n Log√≠stica muestra el AUC m√°s alto con 0.84 tanto en el escenario 'SMOTE' como en 'Undersampling'.
Gradient Boosting tambi√©n logra 0.84 en los escenarios 'SMOTE' y 'Undersampling'.
LightGBM alcanza 0.84 en los escenarios 'SMOTE' y 'Undersampling'.
CatBoost tambi√©n muestra un rendimiento fuerte con 0.84 en el escenario 'Undersampling' y 0.83 en 'SMOTE'.

3. Puntuaci√≥n F1 (Churn)
![](./img/3_Metrica_F1.png)

Puntuaci√≥n F1 (Churn) m√°s alta: Esta m√©trica es crucial para equilibrar la precisi√≥n y el recall en la clase minoritaria.
LightGBM y Gradient Boosting consistentemente logran las puntuaciones F1 m√°s altas para 'Churn' con 0.62 en los escenarios 'SMOTE' y 'Undersampling'.
CatBoost tambi√©n se desempe√±a muy bien, alcanzando 0.62 en el escenario 'Undersampling' y 0.61 con SMOTE.
Impacto del Balanceo: Tanto SMOTE como Undersampling mejoran significativamente la puntuaci√≥n F1 para la clase 'Churn' en comparaci√≥n con el escenario 'No Balancing', que generalmente oscila entre 0.52 y 0.59.

4. Recall (Churn)
![](./img/4_Metrica_Recall.png)

Recall (Churn) m√°s alto: Esta m√©trica indica la capacidad del modelo para identificar a todos los clientes que realmente abandonan el servicio.
Regresi√≥n Log√≠stica se destaca con el Recall m√°s alto para 'Churn' con 0.80 en los escenarios 'SMOTE' y 'Undersampling'.
Gradient Boosting tambi√©n muestra un Recall muy fuerte para 'Churn' con 0.79-0.80 en los escenarios 'SMOTE' y 'Undersampling'.
CatBoost tambi√©n se desempe√±a fuertemente con 0.79 en el escenario 'Undersampling' y 0.71 con SMOTE.

Impacto del Balanceo: Los m√©todos de balanceo (SMOTE y Undersampling) mejoran dr√°sticamente el Recall para 'Churn' en todos los modelos, pasando de rangos como 0.47-0.54 (sin balanceo) a 0.70-0.80.

Resumen de los Modelos y Escenarios con Mejor Rendimiento:
Bas√°ndonos en estas observaciones, y con un enfoque particular en las m√©tricas espec√≠ficas de 'Churn' (Puntuaci√≥n F1 y Recall), que a menudo son m√°s cr√≠ticas en los problemas de predicci√≥n de abandono:

* Para maximizar el Recall (Churn):

La Regresi√≥n Log√≠stica con SMOTE/Undersampling y **Gradient Boosting** con SMOTE/Undersampling son las mejores opciones. Estos modelos son los m√°s efectivos para identificar la mayor proporci√≥n de clientes que abandonar√°n el servicio.

* Para equilibrar la Precisi√≥n y el Recall (Puntuaci√≥n F1 de Churn):

LightGBM con SMOTE/Undersampling y **Gradient Boosting** con SMOTE/Undersampling son los de mayor rendimiento. Ofrecen un buen compromiso entre no pasar por alto a los clientes que abandonan y no se√±alar err√≥neamente a demasiados clientes que no lo har√°n.

* Para maximizar el Discriminatorio General (AUC):

Regresi√≥n Log√≠stica, **Gradient Boosting**, LightGBM y CatBoost (con SMOTE/Undersampling) muestran consistentemente excelentes puntuaciones AUC, lo que indica su capacidad general para distinguir entre el abandono y el no abandono.

Los escenarios de 'SMOTE' y 'Undersampling' son cruciales para mejorar la detecci√≥n de la clase minoritaria 'Churn'.

---->> Bas√°ndonos en la evaluaci√≥n de los modelos, el **LightGBM** y **Gradient Boosting** cuando se utilizan con SMOTE o Undersampling, se encuentran consistentemente entre los de mayor rendimiento en AUC, Puntuaci√≥n F1 (Churn) y Recall (Churn).

## **üéØSeleccion Modelo**

El modelo **Gradient Boosting** se destac√≥ como uno de los modelos con el mejor desempe√±o global para la predicci√≥n de churn. 

El modelo Gradient Boosting es una opci√≥n robusta para la predicci√≥n de churn, especialmente si la estrategia de negocio prioriza la **confiabilidad de las alertas de churn** (es decir, reducir al m√≠nimo las intervenciones innecesarias sobre clientes que no tienen intenci√≥n real de irse). Su alta precisi√≥n para la clase 'Churn' asegura que los recursos de retenci√≥n se dirijan a los clientes con mayor probabilidad de abandono real, optimizando la eficacia de las campa√±as.

Comparaci√≥n de las m√©tricas clave para la clase Churn con Gradient Boosting bajo ambos balanceos SMOTE y Undersampling:

M√©trica(Churn)	Gradient Boosting (SMOTE)	Gradient Boosting (Undersampling)
Precision         	   **0.51**	                    0.50
Recall	               0.79	                        **0.80**
F1-Score	             **0.62**	                    0.61
AUC	                   **0.84**	                    **0.84**
Accuracy	             **0.75**	                    0.73
An√°lisis:

Priorizaci√≥n del Recall: Si el objetivo principal es detectar la mayor cantidad posible de clientes en riesgo de churn (priorizando el Recall), el Undersampling (0.80) ofrece una ventaja marginal sobre SMOTE (0.79) para el Gradient Boosting.

Equilibrio entre detecci√≥n y fiabilidad (F1-Score y Precision): Al buscar un equilibrio s√≥lido donde no solo detecte a muchos churners (Recall) sino que tambi√©n tenga una buena fiabilidad en esas predicciones (Precision) y un buen balance general (F1-Score), SMOTE (F1-Score: 0.62, Precision: 0.51) tiene una ligera ventaja sobre Undersampling (F1-Score: 0.61, Precision: 0.50).

Selecci√≥n:

Dado que el objetivo es priorizar el Recall pero tambi√©n buscar un equilibrio s√≥lido en el F1-Score y Precision, la elecci√≥n es muy ajustada. **Gradient Boosting con SMOTE** es una opci√≥n ligeramente m√°s robusta al ofrecer un F1-Score y Precision de Churn marginalmente mejores, mientras que su Recall es casi id√©ntico al de Undersampling. Esto podr√≠a traducirse en un modelo que genera un poco menos de falsos positivos (mayor precisi√≥n) mientras sigue siendo excelente en la identificaci√≥n de churners (alto recall).
---

## üìà 8. Estrategia de Riesgo y Negocio

# Estrategias Propuestas de Retenci√≥n seg√∫n Probabilidad de Churn

üëâ [Ver Estrategias](./img/Estrategias.png)

El output del modelo se conecta con una **tabla de estrategias**, segmentando clientes en **rangos de probabilidad**:

Esto permite traducir el modelo en **acciones concretas de negocio**.

---

## üì¶ 9. Serializaci√≥n e Integraci√≥n

* El pipeline completo fue **serializado en formato `.pkl`** usando `joblib`.
* El modelo es consumido por un **microservicio FastAPI**, que expone un endpoint `/predict`.
* La API retorna:

```json
{
  "prevision": "Va a cancelar",
  "probabilidad": 0.81
}
```

---

## ‚úÖ 10. Conclusiones

* El churn puede ser **anticipado de forma confiable** usando variables de comportamiento y contrato.
* La integraci√≥n DS ‚Üî Backend permite llevar el modelo a un entorno cercano a producci√≥n.
* ChurnInsight demuestra el valor de la ciencia de datos aplicada a problemas reales de negocio.

---

## üìù Licencia

Este proyecto fue desarrollado como parte del Hackaton ONE - Equipo 46.

## üìû Contacto

Para preguntas o soporte, contacta al equipo de desarrollo.

---

**Desarrollado con ‚ù§Ô∏è por el Equipo 46 - Hackaton ONE**
